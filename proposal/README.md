# Long-form Question Answering (LFQA)

>   Jingsong Gao, jg2109
>
>   Qinren Zhou, qz142
>
>   Rui Qiu rq47



## Introduction

The search engines nowadays enable us to ask any questions as a search query. However, when it comes to a scientific question, the answer to that question could be either not accurate enough or too specialized to understand. For instance, to fully apprehend a Wikipedia page, one might need much prior knowledge in a particular area. 

Prior research on long-form question answering aims to fix this issue. [ELI5: Long Form Question Answering](https://arxiv.org/abs/1907.09190) by Facebook (2019) and [Hurdles to Progress in Long-form Question Answering](https://arxiv.org/abs/2103.06332) by Google (2021) are two representative papers in this area. Our project will primarily focus on reproducing their results and try to gain some minor improvements.

## Data

The subreddit r/explainlikeim5 (ELI5) from Reddit seems to be a worthy training dataset. Users in this subreddit are known for their objective, thorough and intuitive explanations of various questions. ELI5 is appealing because answers are supposed to be entirely self-contained and thus rely less on pre-existing knowledge of the world and use more straightforward language that is easier to model.

We intend to focus on the existing ELI5 dataset from Hugging Face. The dataset contains more than 270,000 records from the subreddit, and each record consists of a scientific question and some easy-to-understand answers. Also, we will use the [Wikipedia dataset](https://dumps.wikimedia.org/backup-index.html) as the ground truth to support our model answering those questions.

## Evaluation

For long-form answers generated by the model, many aspects need to be evaluated, such as topical, accuracy, fluency, and coherence. We will use ROUGE metrics to measure the similarity between the model output and standard answers in the ELI5 dataset to evaluate whether the model output is accurate and relevant to the topic. In addition, we will also introduce some human evaluations to see whether answers are fluent in presentation and coherent from start to end.

## Model

Since our project prioritizes recreating the experiment results, ideally, we intend to train the following models compared in the paper.

The baseline models are extractive models based on (1) naïvely following the TFIDF similarity and (2) BidAF.

-   Baseline models (extractive models):

    -   (1) Naïve TFIDF model. Find seven sentences from the support document with the highest TFIDF similarity with the question.
    -   (2) BidAF model. Find a span of up to 5 continuous sentences in the support document with the highest ROGUE with the reference answer, then sub-sample other support document sentences to generate a document shorter than 400 words. The model predicts the extracted span in such a document.

-   Models of interests (abstractive models):

    -   (3) Language model (Q + A)
    -   (4) Language model (Q + D + A)
    -   (5) Seq2Seq configuration (Q to A)
    -   (6) Seq2Seq configuration (Q + D to A)
    -   (7) Seq2Seq with multi-tasks including language modeling (Q + D + A), source/target pairs, and masked word prediction.

## Challenge

When we first proposed this topic, we thought that the most considerable difficulty might be: ==(1) we did not know how to build the model==, ==(2) the trained model could not give any meaningful answers==. Nevertheless, with further literature searching, the approach of Facebook and Google gave us enough theoretical support. Hence, the challenge of this research turned into: whether we have enough computing resources to reproduce the training procedures in two papers and whether we can make any improvements to the model. Given that we are still beginners in NLP, we suggest that the criterion of success in this project be defined as partially reproducing the result of two papers.

## Expectation & Demonstration

We expect to obtain an NLP model that can give reliable, detailed, and easy-to-understand answers to scientific questions. We can build a QA chatbot or an interactive web app based on this model. Users can get answers either by asking the chatbot questions or by inputting questions on the web page. In addition, a research report will record the research process and conclusion, and this report will serve as documentation and guide for this project.

